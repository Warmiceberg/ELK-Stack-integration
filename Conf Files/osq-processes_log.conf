########################
# 
#  Copyright (c) 2015, Next Generation Intelligent Networks (nextGIN), RC.
#  Institute of Space Technology
#  All rights reserved.
# 
#  This source code is licensed under the BSD-style license found in the
#  LICENSE file in the root directory of this source tree. An additional grant
#  of patent rights can be found in the PATENTS file in the same directory.
#
########################

input {
  file {
    type => "osq-processes_log"
    start_position => "end"
    sincedb_path => "/var/tmp/.osq-processes_sincedb"

    #Edit the following path to reflect the location of your log files. You can also change the extension if you use something else
    path => "/home/sami2316/bro-logs/osq-processes.log"
  }
}

filter {

  #Let's get rid of those header lines; they begin with a hash
  if [message] =~ /^#/ {
    drop { }
  }

  #Now, using the csv filter, we can define the Bro log fields
  if [type] == "osq-processes_log" {
    csv {

      #osq-processes.log:#fields	t	host	mode	pid	ppid	uid	euid	gid	egid	argv
      columns => ["t","host","mode","pid","ppid","path","uid","euid","gid","egid","argv"]

      #If you use a custom delimiter, change the following value in between the quotes to your delimiter. Otherwise, leave the next line alone.
      separator => "	"
    }

    #Let's convert our timestamp into the 't' field, so we can use Kibana features natively
    date {
      match => [ "t", "UNIX" ]
    }
    mutate {
      convert => [ "pid", "integer" ]
      convert => [ "ppid", "integer" ]
      convert => [ "uid", "integer" ]
      convert => [ "euid", "integer" ]
      convert => [ "gid", "integer" ]
      convert => [ "egid", "integer" ]
    }
  }
}

output {
  # stdout { codec => rubydebug }
  elasticsearch { hosts => ["localhost"] }
}
